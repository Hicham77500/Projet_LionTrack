groups:
  # ========== KAFKA ALERTS ==========
  - name: kafka.rules
    interval: 30s
    rules:
      - alert: KafkaBrokerDown
        expr: up{job="kafka"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Kafka broker is down"
          description: "Kafka broker {{ $labels.instance }} has been down for more than 5 minutes"

      - alert: KafkaHighConsumerLag
        expr: kafka_consumer_lag{topic=~"lions.*|users.*|challenges.*"} > 10000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High Kafka consumer lag"
          description: "Consumer lag is {{ $value }} messages for topic {{ $labels.topic }}"

  # ========== POSTGRESQL ALERTS ==========
  - name: postgres.rules
    interval: 30s
    rules:
      - alert: PostgreSQLDown
        expr: up{job="postgres"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL server {{ $labels.instance }} is down"

      - alert: PostgreSQLHighConnections
        expr: pg_stat_activity_count{state="active"} > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High PostgreSQL connections"
          description: "Active connections: {{ $value }}"

      - alert: PostgreSQLSlowQueries
        expr: pg_slow_queries > 10
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High number of slow queries"
          description: "{{ $value }} slow queries detected"

  # ========== SPARK ALERTS ==========
  - name: spark.rules
    interval: 30s
    rules:
      - alert: SparkMasterDown
        expr: up{job="spark-master"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Spark Master is down"
          description: "Spark Master has been unreachable for 5 minutes"

      - alert: SparkWorkerDown
        expr: up{job="spark-worker"} == 0
        for: 5m
        labels:
          severity: high
        annotations:
          summary: "Spark Worker is down"
          description: "Spark Worker {{ $labels.instance }} is not responding"

  # ========== DATA QUALITY ALERTS ==========
  - name: data_quality.rules
    interval: 60s
    rules:
      - alert: DataQualityDegraded
        expr: avg(liontrack_data_quality_score{table=~"bronze.*|silver.*"}) < 80
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Data quality score below threshold"
          description: "Average quality score: {{ $value }}%"

      - alert: PipelineFailed
        expr: liontrack_pipeline_status{status="failed"} == 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Data pipeline has failed"
          description: "Pipeline {{ $labels.pipeline_name }} failed at {{ $labels.timestamp }}"

      - alert: HighDataLatency
        expr: liontrack_ingestion_latency_seconds > 300
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High data ingestion latency"
          description: "Latency: {{ $value }}s (threshold: 300s)"

  # ========== AIRFLOW ALERTS ==========
  - name: airflow.rules
    interval: 60s
    rules:
      - alert: AirflowDAGFailed
        expr: airflow_dag_status{status="failed"} == 1
        for: 5m
        labels:
          severity: high
        annotations:
          summary: "Airflow DAG has failed"
          description: "DAG {{ $labels.dag_id }} failed"

      - alert: AirflowTaskLongRunning
        expr: airflow_task_duration_seconds > 3600
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Long running Airflow task"
          description: "Task running for {{ $value }}s"

  # ========== SYSTEM ALERTS ==========
  - name: system.rules
    interval: 30s
    rules:
      - alert: DiskSpaceRunningOut
        expr: node_filesystem_avail_bytes{mpount="/"} / node_filesystem_size_bytes < 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space"
          description: "Only {{ $value | humanize }}B remaining"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage: {{ $value | humanizePercentage }}"

      - alert: HighCPUUsage
        expr: avg(rate(node_cpu_seconds_total{mode!="idle"}[5m])) > 0.8
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage: {{ $value | humanizePercentage }}"
