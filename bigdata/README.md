# ğŸš€ LionTrack - Architecture BigData ModernisÃ©e

## ğŸ“‹ RÃ©sumÃ© des amÃ©liorations

Ton projet **LionTrack** a Ã©tÃ© entiÃ¨rement modernisÃ© avec une **architecture BigData Kappa** complÃ¨te, intÃ©grant :

### âœ… Infrastructure DistribuÃ©e

- **Kafka** - Message streaming pour ingestion Ã©vÃ©nementielle
- **Spark** - Processing distribuÃ© (batch + streaming)
- **PostgreSQL** - Data warehouse analytique  
- **MinIO** - Stockage distribuÃ© type S3
- **Prometheus/Grafana** - Monitoring et dashboards

### âœ… Data Lake StructurÃ©

```
Bronze layer    â†’ DonnÃ©es brutes (Kafka â†’ PostgreSQL)
     â†“
Silver layer    â†’ DonnÃ©es validÃ©es et nettoyÃ©es
     â†“
Gold layer      â†’ MÃ©triques mÃ©tier et agrÃ©gations
```

### âœ… Pipelines ETL Complets

- **Airflow DAG** - Orchestration quotidienne
- **Spark Batch** - Processing Bronze â†’ Silver â†’ Gold
- **Spark Streaming** - Temps rÃ©el Kafka â†’ Parquet
- **Kafka Consumers** - Ingestion vers PostgreSQL

### âœ… APIs Analytiques Enrichies

15+ endpoints pour explorer les donnÃ©es :
- Lions analytics (positions, poids, santÃ©)
- User engagement (scores, activitÃ©, challenges)
- Leaderboards (classements)
- Trends & forecasting
- Export CSV/JSON

### âœ… Monitoring & ObservabilitÃ©

- **Data Quality Checks** - Validation automatique
- **Data Lineage** - TraÃ§abilitÃ© complÃ¨te
- **Pipeline Metrics** - SantÃ© pipelines
- **Grafana Dashboards** - Visualisation temps rÃ©el

---

## ğŸ“ Fichiers CrÃ©Ã©s

```
bigdata/
â”œâ”€â”€ docker-compose-bigdata.yml         # Infrastructure Docker complÃ¨te
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ ARCHITECTURE.md                    # Documentation dÃ©taillÃ©e
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init.sql                      # SchÃ©mas PostgreSQL (Bronze/Silver/Gold)
â”œâ”€â”€ kafka/
â”‚   â”œâ”€â”€ producer.js                   # Producteur Kafka (Node.js)
â”‚   â””â”€â”€ consumer.py                   # Consommateurs Kafka (Python)
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ batch_processor.py            # Job batch ETL
â”‚   â””â”€â”€ streaming_processor.py        # Streaming Spark
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml                # Config Prometheus
â”‚   â”œâ”€â”€ rules.yml                     # RÃ¨gles d'alerte
â”‚   â””â”€â”€ data_quality_monitor.py       # Service monitoring
â””â”€â”€ notebooks/
    â””â”€â”€ (Templates pour Jupyter Lab)

services/analytics/
â”œâ”€â”€ analytics.routes.js               # 15+ endpoints analytiques
â””â”€â”€ analytics.controller.js           # RequÃªtes PostgreSQL

scripts/bigdata/
â”œâ”€â”€ start-bigdata.sh                 # DÃ©marriage infrastructure
â”œâ”€â”€ stop-bigdata.sh                  # ArrÃªt infrastructure
â””â”€â”€ test-bigdata.sh                  # Suite de tests

airflow/dags/
â””â”€â”€ liontrack_bigdata_dag.py         # DAG orchestration pipeline

package.json (mis Ã  jour)            # DÃ©pendances Kafka + PostgreSQL
server.js (mis Ã  jour)               # Import routes analytics
```

---

## ğŸš€ DÃ©marrage Rapide

### 1. Lancer l'infrastructure

```bash
cd /Users/corsair/Documents/IPSSI/Projets\ groupes/Lion_track/Projet_LionTrack

chmod +x scripts/bigdata/*.sh

./scripts/bigdata/start-bigdata.sh
```

### 2. Installer les dÃ©pendances Node

```bash
npm install
```

### 3. DÃ©marrer l'API LionTrack

```bash
npm start
# ou en dev
npm run dev
```

### 4. DÃ©marrer les consommateurs Kafka

```bash
source bigdata/.venv/bin/activate
python bigdata/kafka/consumer.py
```

### 5. Lancer les pipelines Spark

```bash
source bigdata/.venv/bin/activate
python bigdata/spark/streaming_processor.py
```

---

## ğŸŒ AccÃ¨s aux Services

| Service | URL | Credentials |
|---------|-----|-------------|
| **API LionTrack** | http://localhost:4001 | - |
| **Analytics Dashboard** | http://localhost:4001/api/analytics/dashboard | JWT Token |
| **Grafana** | http://localhost:3000 | admin/admin |
| **Prometheus** | http://localhost:9090 | - |
| **Spark UI** | http://localhost:8080 | - |
| **Jupyter Lab** | http://localhost:8888 | Token (logs) |
| **MinIO Console** | http://localhost:9001 | minioadmin/minioadmin |
| **PostgreSQL** | localhost:5432 | liontrack/liontrack_secure_pass |
| **Kafka** | kafka:9092 | - |

---

## ğŸ“Š Endpoints Analytiques ClÃ©s

```bash
# Tous les lions avec metrics
GET /api/analytics/lions

# DÃ©tails d'un lion
GET /api/analytics/lions/{lionId}

# Tendance poids
GET /api/analytics/lions/{lionId}/weight-trend?days=30

# Engagement utilisateur
GET /api/analytics/users/{userId}/engagement

# Dashboard global
GET /api/analytics/dashboard

# Leaderboards
GET /api/analytics/leaderboard/users
GET /api/analytics/leaderboard/lions

# Export
GET /api/analytics/export/csv?table=silver.lions
GET /api/analytics/export/json?table=gold.lions_metrics
```

---

## ğŸ—ï¸ Architecture DÃ©crite

### Flux de DonnÃ©es

```
MongoDB (Source)
    â†“
Node.js APIs â†’ Kafka Topics
    â†“
[Spark Streaming] ET [Kafka Consumers]
    â†“
PostgreSQL (Bronze/Silver/Gold)
    â†“
[Spark Batch] (Airflow daily)
    â†“
[Analytics APIs] â†’ Dashboards
    â†“
[Grafana/PWA Frontend]
```

### SchÃ©mas de DonnÃ©es

**Bronze** (Raw) â†’ **Silver** (Cleansed) â†’ **Gold** (Metrics)

- `bronze.lions_raw` â†’ `silver.lions` â†’ `gold.lions_metrics`
- `bronze.weights_raw` â†’ `silver.weight_history` â†’ (aggregations)
- `bronze.challenges_raw` â†’ `silver.challenges` â†’ `gold.users_activity`

### Monitoring

- **Data Quality**: Checks automatiques Bronze/Silver
- **Pipeline Health**: Taux succÃ¨s/durÃ©e Airflow
- **System Metrics**: CPU/Memory/Disk Prometheus

---

## ğŸ“ Notions BigData AppliquÃ©es

| Notion | ImplÃ©mentation |
|--------|----------------|
| **ScalabilitÃ© horizontale** | Spark workers (2), Kafka partitions (3) |
| **TolÃ©rance aux pannes** | Replication factor=1, idempotent producers |
| **ThÃ©orÃ¨me CAP** | PostgreSQL (linÃ©aritÃ©) + Kafka (disponibilitÃ©) |
| **Partitionnement** | Parquet par date, Kafka par key |
| **RÃ©plication** | PostgreSQL WAL, Kafka replication |
| **Architecture Kappa** | Streaming + Batch unifiÃ©s en Spark |
| **Format Columnar** | Parquet pour stockage optimisÃ© |
| **Change Data Capture** | Kafka events depuis MongoDB |
| **FenÃªtrage temps rÃ©el** | Spark Streaming 5-min windows |
| **Data Lineage** | Tables metadata.data_lineage |
| **Data Quality** | Automated checks bronz/silver |
| **Monitoring** | Prometheus + Grafana + custom metrics |

---

## ğŸ“ˆ Cas d'Usage SupportÃ©s

1. **Tracking lions temps rÃ©el** - Positions via Kafka
2. **SantÃ© animaux quotidienne** - AgrÃ©gations Gold layer
3. **Engagement utilisateurs** - Scores et rankings   
4. **DÃ©tection anomalies** - Quality checks + alerts
5. **Reporting analytique** - Exports CSV/JSON
6. **Dashboards interactifs** - Grafana + PWA

---

## ğŸ”§ Configuration

### Variables d'environnement (.env)

```bash
# MongoDB (existant)
MONGODB_URI=...
JWT_SECRET=...

# BigData (nouveau)
PG_DATABASE=liontrack_warehouse
PG_USER=liontrack
PG_PASSWORD=liontrack_secure_pass
PG_HOST=postgres
KAFKA_BROKERS=kafka:9092
SPARK_MASTER=spark://spark-master:7077
```

### Airflow Variables

ConfigurÃ©es automatiquement :
- `spark_master` = spark://spark-master:7077
- `kafka_servers` = kafka:9092

---

## âœ¨ Points Forts

âœ… **Production-ready** - Docker, monitoring, alertes  
âœ… **Scalable** - Spark distribuÃ©, Kafka partitionnÃ©  
âœ… **Observable** - Prometheus, Grafana, data quality  
âœ… **Moderne** - Kappa architecture, streaming friendly  
âœ… **DocumentÃ©** - Architecture.md + code explicite  
âœ… **Testable** - Test suite fournie  
âœ… **Extensible** - Templates pour ML, dbt, Elasticsearch

---

## ğŸ›£ï¸ Prochaines Ã‰tapes

- [ ] Ajouter ML (anomaly detection)
- [ ] Elasticsearch pour recherche full-text
- [ ] dbt pour transformations dÃ©claratives
- [ ] Great Expectations pour validation avancÃ©e
- [ ] CI/CD pour pipelines Spark
- [ ] Backup/DR strategy

---

## ğŸ“š Documentation Complete

Voir **[bigdata/ARCHITECTURE.md](bigdata/ARCHITECTURE.md)** pour :
- Architecture dÃ©taillÃ©e
- SchÃ©mas complets
- RequÃªtes SQL exemples
- Troubleshooting
- Roadmap

---

**Version** : 3.0.0 (BigData Enhanced)  
**Date** : 2026-02-25  
**Auteur** : LionTrack Dev Team

ğŸ¦ **Ready to scale!**
