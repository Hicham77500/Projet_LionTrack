# ðŸ¦ LionTrack - Architecture BigData Kappa

## Vue d'ensemble

LionTrack a Ã©tÃ© modernisÃ© avec une **Architecture Kappa** complÃ¨te pour gÃ©rer les donnÃ©es de tracking des lions Ã  grande Ã©chelle. Cette architecture combine le streaming temps rÃ©el avec l'analytique batch dans une pipeline unifiÃ©e.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SOURCES DE DONNÃ‰ES                              â”‚
â”‚  (MongoDB - Lions, Users, Challenges, Weights)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    KAFKA TOPICS               â”‚
         â”‚  â–ª lions.position.events      â”‚
         â”‚  â–ª lions.weight.events        â”‚
         â”‚  â–ª users.activity.events      â”‚
         â”‚  â–ª challenges.status.events   â”‚
         â”‚  â–ª data.quality.events        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                       â”‚
         â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SPARK    â”‚          â”‚   SPARK    â”‚
    â”‚  STREAMING â”‚          â”‚   BATCH    â”‚
    â”‚(Real-time) â”‚          â”‚(Scheduled) â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   DATA LAKE (PARQUET)       â”‚
        â”‚  â–ª Bronze (Raw)             â”‚
        â”‚  â–ª Silver (Cleansed)        â”‚
        â”‚  â–ª Gold (Business Metrics)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                         â”‚
      â–¼                         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚PostgreSQL   â”‚       â”‚Analytics API â”‚
  â”‚ Warehouse   â”‚       â”‚(JSON/CSV)    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                         â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   DASHBOARDS            â”‚
        â”‚  â–ª Grafana              â”‚
        â”‚  â–ª PWA Frontend         â”‚
        â”‚  â–ª Kibana (optionnel)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ—ï¸ Composants Infrastructure

### 1. **Kafka (Message Streaming)**
- **Service**: `kafka:9092`
- **Topics**:
  - `lions.position.events` - Positions GPS des lions
  - `lions.weight.events` - Mesures de poids
  - `users.activity.events` - ActivitÃ©s utilisateur
  - `challenges.status.events` - Changements de challenge
  - `data.quality.events` - Rapports de qualitÃ©

### 2. **Spark (Distributed Computing)**
- **Master**: `spark://spark-master:7077`
- **Workers**: 2 workers (2GB RAM, 2 cores chacun)
- **Jobs**:
  - Batch: Traitement quotidien (Bronze â†’ Silver â†’ Gold)
  - Streaming: Traitement temps rÃ©el des Ã©vÃ©nements

### 3. **PostgreSQL (Data Warehouse)**
- **Service**: `postgres:5432`
- **Database**: `liontrack_warehouse`
- **SchÃ©mas**:
  - `bronze.*` - DonnÃ©es brutes du Kafka
  - `silver.*` - DonnÃ©es nettoyÃ©es et validÃ©es
  - `gold.*` - MÃ©triques mÃ©tier et agrÃ©gations
  - `metadata.*` - Data lineage et qualitÃ©

### 4. **MinIO (Object Storage)**
- **Service**: `minio:9000`
- **Console**: `minio:9001`
- **Usage**: Stockage distribuÃ© pour les donnÃ©es Parquet

### 5. **Monitoring Stack**
- **Prometheus**: `prometheus:9090` (mÃ©triques)
- **Grafana**: `grafana:3000` (dashboards)

---

## ðŸ“Š ModÃ¨le DonnÃ©es

### Bronze Layer (Raw Data)
```sql
bronze.lions_raw
â”œâ”€â”€ lion_id (PK)
â”œâ”€â”€ name
â”œâ”€â”€ position_lat, position_lng
â”œâ”€â”€ last_update
â”œâ”€â”€ metadata (JSONB)
â””â”€â”€ partition_date

bronze.weights_raw
â”œâ”€â”€ weight_id (PK)
â”œâ”€â”€ lion_id (FK)
â”œâ”€â”€ weight, unit
â”œâ”€â”€ measured_at
â””â”€â”€ metadata (JSONB)

bronze.challenges_raw
â”œâ”€â”€ challenge_id (PK)
â”œâ”€â”€ user_id (FK)
â”œâ”€â”€ title, status
â””â”€â”€ metadata (JSONB)
```

### Silver Layer (Cleaned & Validated)
```sql
silver.lions
â”œâ”€â”€ lion_id (PK)
â”œâ”€â”€ name
â”œâ”€â”€ position_lat, position_lng
â”œâ”€â”€ status
â”œâ”€â”€ data_quality_score
â””â”€â”€ dw_update_date

silver.weight_history
â”œâ”€â”€ lion_id (FK)
â”œâ”€â”€ weight, unit
â””â”€â”€ measured_at

silver.challenges
â”œâ”€â”€ challenge_id (PK)
â”œâ”€â”€ user_id (FK)
â”œâ”€â”€ title, status
â””â”€â”€ updated_at
```

### Gold Layer (Business Metrics)
```sql
gold.lions_metrics
â”œâ”€â”€ lion_id, metric_date (PK)
â”œâ”€â”€ avg_weight
â”œâ”€â”€ weight_trend
â”œâ”€â”€ health_score (0-100)
â””â”€â”€ tracking_frequency

gold.users_activity
â”œâ”€â”€ user_id, activity_date (PK)
â”œâ”€â”€ challenges_completed
â”œâ”€â”€ weight_entries
â””â”€â”€ engagement_score

gold.lions_positions_history
â”œâ”€â”€ lion_id, position_date (PK)
â”œâ”€â”€ lat, lng
â””â”€â”€ accuracy
```

---

## ðŸš€ DÃ©marrage de l'infrastructure

### 1. DÃ©marrer Docker Compose

```bash
# DÃ©marrer tous les services
docker-compose -f docker-compose-bigdata.yml up -d

# VÃ©rifier le statut
docker-compose -f docker-compose-bigdata.yml ps

# Voir les logs
docker-compose -f docker-compose-bigdata.yml logs -f kafka
```

### 2. Initialiser la base de donnÃ©es

```bash
# La BD PostgreSQL se crÃ©e automatiquement via le script init.sql

# VÃ©rifier la crÃ©ation
docker exec postgres-container psql -U liontrack -d liontrack_warehouse -c "\dt+"
```

### 3. DÃ©marrer les consommateurs Kafka

```bash
# Installation des dÃ©pendances
pip install -r bigdata/requirements.txt

# DÃ©marrer les consommateurs
python bigdata/kafka/consumer.py
```

### 4. DÃ©marrer les pipelines Spark

```bash
# Batch processing (via Airflow)
# Les DAGs se lancent automatiquement Ã  2h du matin

# Streaming (Ã  la demande)
python bigdata/spark/streaming_processor.py
```

---

## ðŸ“¡ Producteurs de DonnÃ©es

### Dans MongoDB â†’ Kafka

Quand un changement survient en MongoDB, on envoie l'Ã©vÃ©nement vers Kafka :

```javascript
// services/weight/weight.controller.js
const producer = new LionTrackKafkaProducer();

exports.addWeight = async (req, res) => {
  const weight = new Weight(req.body);
  await weight.save();
  
  // Envoyer vers Kafka
  await producer.publishWeight(weight);
  
  res.json({success: true, data: weight});
};
```

### Topics Kafka et Consommateurs

| Topic | Producteur | Consommateur | Destination |
|-------|-----------|--------------|-------------|
| `lions.position.events` | Node.js | Consumer Python | bronze.lions_raw |
| `lions.weight.events` | Node.js | Spark Streaming | bronze.weights_raw |
| `users.activity.events` | Node.js | Spark Streaming | bronze.users_raw |
| `data.quality.events` | Monitor | Metadata | metadata.data_quality_checks |

---

## ðŸ”„ Pipelines ETL

### Pipeline Batch (Quotidien - 2h du matin)

1. **Airflow DAG**: `liontrack_bigdata_pipeline`
2. **Ã‰tapes**:
   - âœ… SantÃ© Kafka & PostgreSQL
   - âœ… Validation qualitÃ© Bronze
   - âœ… Spark Job: Bronze â†’ Silver (nettoyage, validation)
   - âœ… Spark Job: Silver â†’ Gold (agrÃ©gations mÃ©tier)
   - âœ… Refresh vues matÃ©rialisÃ©es
   - âœ… GÃ©nÃ©ration rapport

### Pipeline Streaming (Continu)

1. **Spark Streaming Jobs**
   - Lions position: FenÃªtrage 5 min
   - Weight: Streaming vers Parquet
   - User activity: FenÃªtrage temps rÃ©el

---

## ðŸ“ˆ APIs Analytiques

### Endpoints Disponibles

```bash
# Lions Analytics
GET /api/analytics/lions                          # Tous les lions
GET /api/analytics/lions/{lionId}                 # DÃ©tails lion
GET /api/analytics/lions/{lionId}/weight-trend    # Tendance poids
GET /api/analytics/lions/{lionId}/position-history # Historique position

# Users Analytics
GET /api/analytics/users/{userId}/engagement      # Score engagement
GET /api/analytics/users/{userId}/activity-summary # 30 derniers jours
GET /api/analytics/users/{userId}/challenges-analytics # Challenges

# Global
GET /api/analytics/dashboard                      # Vue complÃ¨te
GET /api/analytics/leaderboard/users              # Classement users
GET /api/analytics/leaderboard/lions              # Classement lions
GET /api/analytics/trends/weight                  # Tendances poids

# Export
GET /api/analytics/export/csv?table=silver.lions  # Export CSV
GET /api/analytics/export/json?table=silver.lions # Export JSON
```

### Exemple RequÃªte

```bash
curl http://localhost:4001/api/analytics/lions \
  -H "Content-Type: application/json"

# RÃ©ponse:
{
  "count": 5,
  "lions": [
    {
      "lion_id": "simba_001",
      "name": "Simba",
      "status": "active",
      "current_weight": 195.5,
      "health_score": 85.2,
      "tracking_frequency": 12,
      "position_lat": -3.3652,
      "position_lng": 29.8185
    }
  ]
}
```

---

## ðŸ” Monitoring & ObservabilitÃ©

### Prometheus MÃ©triques

Les mÃ©triques suivantes sont collectÃ©es :

```
liontrack_pipeline_runs_total{pipeline_name="batch_processor", status="success"}
liontrack_data_quality_score{table_name="bronze.lions_raw"} 95.2
liontrack_pipeline_duration_seconds_bucket{pipeline_name="batch_processor", le="300"}
liontrack_table_records{table_name="silver.lions", layer="silver"} 42
```

### Dashboards Grafana

1. **Pipeline Health**: Taux succÃ¨s, durÃ©e exÃ©cution
2. **Data Quality**: Scores par table, tendances
3. **System Health**: CPU, mÃ©moire, disque
4. **Kafka Metrics**: Lag consommateurs, throughput

### Data Quality Checks

```
metadata.data_quality_checks
â”œâ”€â”€ check_name (bronze_validation, schema_check)
â”œâ”€â”€ table_name (bronze.lions_raw)
â”œâ”€â”€ quality_percentage (95.2%)
â””â”€â”€ details (JSONB)
```

---

## ðŸš¨ Alertes Principales

| Alerte | Seuil | Action |
|--------|--------|--------|
| Kafka Down | - | ðŸ”´ Critical - restart broker |
| PostgreSQL Connections | > 80 | ðŸŸ¡ Warning - investigate |
| Data Quality | < 80% | ðŸŸ¡ Warning - review data |
| Pipeline Failed | status = failed | ðŸ”´ Critical - check logs |
| High Consumer Lag | > 10k messages | ðŸŸ¡ Warning - scale consumers |

---

## ðŸ”§ Configuration

### Variables d'Environnement

```bash
# .env
MONGODB_URI=mongodb+srv://...
JWT_SECRET=...
NODE_ENV=production

# BigData
PG_DATABASE=liontrack_warehouse
PG_USER=liontrack
PG_PASSWORD=liontrack_secure_pass
PG_HOST=postgres
PG_PORT=5432

KAFKA_BROKERS=kafka:9092
SPARK_MASTER=spark://spark-master:7077
```

### Airflow Variables

```bash
spark_master = spark://spark-master:7077
kafka_servers = kafka:9092
postgres_database = liontrack_warehouse
```

---

## ðŸ“ Cas d'Utilisation & RequÃªtes

### 1. SantÃ© globale des lions (quotidien)

```sql
SELECT 
  COUNT(*) FILTER (WHERE health_score > 80) as excellent,
  COUNT(*) FILTER (WHERE health_score BETWEEN 60 AND 80) as good,
  AVG(health_score) as avg_health,
  CURRENT_DATE as report_date
FROM gold.lions_metrics
WHERE metric_date = CURRENT_DATE;
```

### 2. Utilisateurs engagÃ©s ce mois-ci

```sql
SELECT 
  u.username,
  SUM(a.challenges_completed) as challenges_done,
  AVG(a.engagement_score) as avg_engagement
FROM silver.users u
JOIN gold.users_activity a ON u.user_id = a.user_id
WHERE a.activity_date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY u.username
ORDER BY avg_engagement DESC;
```

### 3. Anomalies de poids (lions suspects)

```sql
SELECT 
  l.lion_id,
  l.name,
  m.avg_weight,
  m.weight_trend,
  m.health_score
FROM silver.lions l
JOIN gold.lions_metrics m ON l.lion_id = m.lion_id
WHERE m.metric_date = CURRENT_DATE
  AND m.health_score < 60;
```

---

## ðŸ›£ï¸ Roadmap

- [ ] ML Models pour dÃ©tection anomalies
- [ ] Data Catalog (Atlas)
- [ ] Elasticsearch pour recherche avancÃ©e
- [ ] Streaming mode avec Flink
- [ ] Dbt pour transformation dÃ©clarative
- [ ] Great Expectations pour data validation
- [ ] Dremio pour requÃªtes distribuÃ©es

---

## ðŸ“š Ressources

- [Architecture Kappa](https://milinda.pathirage.org/kappa-architecture.html)
- [Spark Documentation](https://spark.apache.org/docs/latest/)
- [Kafka Best Practices](https://kafka.apache.org/documentation/)
- [PostgreSQL Data Warehouse](https://postgresql.org/)

---

**DerniÃ¨re mise Ã  jour**: 2026-02-25  
**Version**: 3.0.0 (BigData Enhanced)  
**Auteur**: LionTrack Dev Team
