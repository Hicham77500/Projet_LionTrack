#!/bin/bash

# ğŸ¦ LionTrack BigData - Quick Start Guide
# 
# Ce script lance l'infrastructure BigData complÃ¨te
# Usage: ./start-bigdata.sh

set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                 ğŸ¦ LionTrack BigData Quick Start              â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ============================================================================
# STEP 1: VÃ©rifier les prÃ©requis
# ============================================================================

echo -e "\n${BLUE}[1/6]${NC} VÃ©rification des prÃ©requis..."

if ! command -v docker &> /dev/null; then
    echo -e "${RED}âŒ Docker n'est pas installÃ©${NC}"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo -e "${RED}âŒ Docker Compose n'est pas installÃ©${NC}"
    exit 1
fi

if ! command -v python3 &> /dev/null; then
    echo -e "${RED}âŒ Python 3 n'est pas installÃ©${NC}"
    exit 1
fi

echo -e "${GREEN}âœ… Tous les prÃ©requis prÃ©sents${NC}"

# ============================================================================
# STEP 2: CrÃ©er les rÃ©pertoires nÃ©cessaires
# ============================================================================

echo -e "\n${BLUE}[2/6]${NC} CrÃ©ation des rÃ©pertoires de donnÃ©es..."

mkdir -p bigdata/data/{bronze,silver,gold,streaming}
mkdir -p bigdata/checkpoints
mkdir -p bigdata/notebooks
mkdir -p bigdata/spark/jobs
mkdir -p bigdata/kafka
mkdir -p bigdata/monitoring
mkdir -p logs

echo -e "${GREEN}âœ… RÃ©pertoires crÃ©Ã©s${NC}"

# ============================================================================
# STEP 3: DÃ©marrer les services Docker
# ============================================================================

echo -e "\n${BLUE}[3/6]${NC} DÃ©marrage des services Docker..."

docker-compose -f docker-compose-bigdata.yml up -d

echo -e "${YELLOW}â³ Attente du dÃ©marrage des services (30 secondes)...${NC}"
sleep 30

# VÃ©rifier que les services sont up
echo -e "\n${YELLOW}VÃ©rification du statut des services:${NC}"
docker-compose -f docker-compose-bigdata.yml ps

echo -e "${GREEN}âœ… Services Docker dÃ©marrÃ©s${NC}"

# ============================================================================
# STEP 4: Installer les dÃ©pendances Python
# ============================================================================

echo -e "\n${BLUE}[4/6]${NC} Installation des dÃ©pendances Python..."

python3 -m venv bigdata/.venv
source bigdata/.venv/bin/activate
pip install --upgrade pip
pip install -r bigdata/requirements.txt

echo -e "${GREEN}âœ… DÃ©pendances Python installÃ©es${NC}"

# ============================================================================
# STEP 5: Initialiser les donnÃ©es
# ============================================================================

echo -e "\n${BLUE}[5/6]${NC} Initialisation de la base de donnÃ©es..."

# Attendre que PostgreSQL soit vraiment prÃªt
echo -e "${YELLOW}â³ Attente de PostgreSQL...${NC}"
for i in {1..30}; do
    if docker-compose -f docker-compose-bigdata.yml exec -T postgres pg_isready -U liontrack -d liontrack_warehouse &>/dev/null; then
        echo -e "${GREEN}âœ… PostgreSQL prÃªt${NC}"
        break
    fi
    echo -n "."
    sleep 1
done

# CrÃ©er les topics Kafka
echo -e "\n${YELLOW}CrÃ©ation des topics Kafka...${NC}"
docker-compose -f docker-compose-bigdata.yml exec -T kafka kafka-topics --create --topic lions.position.events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 2>/dev/null || true
docker-compose -f docker-compose-bigdata.yml exec -T kafka kafka-topics --create --topic lions.weight.events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 2>/dev/null || true
docker-compose -f docker-compose-bigdata.yml exec -T kafka kafka-topics --create --topic users.activity.events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 2>/dev/null || true
docker-compose -f docker-compose-bigdata.yml exec -T kafka kafka-topics --create --topic challenges.status.events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 2>/dev/null || true
docker-compose -f docker-compose-bigdata.yml exec -T kafka kafka-topics --create --topic data.quality.events --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 2>/dev/null || true

echo -e "${GREEN}âœ… Topics Kafka crÃ©Ã©s${NC}"

# ============================================================================
# STEP 6: Afficher les URLs d'accÃ¨s
# ============================================================================

echo -e "\n${BLUE}[6/6]${NC} Infrastructure prÃªte ! ${GREEN}âœ…${NC}"

echo -e "\n${YELLOW}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${YELLOW}â•‘              Services disponibles sur votre machine              â•‘${NC}"
echo -e "${YELLOW}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}\n"

echo -e "${GREEN}ğŸ“Š Dashboards & Monitoring:${NC}"
echo -e "  ğŸ”´ Prometheus  : http://localhost:9090"
echo -e "  ğŸ“ˆ Grafana     : http://localhost:3000 (admin/admin)"
echo -e "  âš™ï¸  Spark UI    : http://localhost:8080"
echo -e "  ğŸ““ Jupyter Lab : http://localhost:8888"

echo -e "\n${GREEN}ğŸ—„ï¸  Stockage & Base de donnÃ©es:${NC}"
echo -e "  ğŸª£ MinIO       : http://localhost:9001 (minioadmin/minioadmin)"
echo -e "  ğŸ˜ PostgreSQL  : localhost:5432 (liontrack/liontrack_secure_pass)"
echo -e "  ğŸ—„ï¸  MongoDB    : Atlas (voir .env)"

echo -e "\n${GREEN}ğŸ¦ APIs LionTrack:${NC}"
echo -e "  ğŸ”— API REST    : http://localhost:4001"
echo -e "  ğŸ“± Analytics   : http://localhost:4001/api/analytics/dashboard"

echo -e "\n${GREEN}ğŸ“¦ Message Broker:${NC}"
echo -e "  ğŸ”” Kafka       : kafka:9092 (interne Docker)"
echo -e "  ğŸ“ Topics      : lions.position.events, lions.weight.events, ..."

echo -e "\n${YELLOW}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}\n"

# ============================================================================
# INSTRUCTIONS SUIVANTES
# ============================================================================

echo -e "${BLUE}ğŸš€ Prochaines Ã©tapes:${NC}\n"

echo -e "${YELLOW}1. DÃ©marrer les consommateurs Kafka:${NC}"
echo -e "   source bigdata/.venv/bin/activate"
echo -e "   python bigdata/kafka/consumer.py\n"

echo -e "${YELLOW}2. DÃ©marrer les pipelines Spark (streaming):${NC}"
echo -e "   source bigdata/.venv/bin/activate"
echo -e "   python bigdata/spark/streaming_processor.py\n"

echo -e "${YELLOW}3. VÃ©rifier les donnÃ©es en PostgreSQL:${NC}"
echo -e "   psql -h localhost -U liontrack -d liontrack_warehouse"
echo -e "   SELECT COUNT(*) FROM silver.lions;\n"

echo -e "${YELLOW}4. Consulter le dashboard:${NC}"
echo -e "   curl http://localhost:4001/api/analytics/dashboard\n"

echo -e "${BLUE}âœ¨ Installation terminÃ©e ! Bon tracking ! ğŸ¦${NC}\n"

# ============================================================================
# Afficher les logs
# ============================================================================

echo -e "${YELLOW}ğŸ“‹ Logs en direct (Ctrl+C pour quitter):${NC}"
docker-compose -f docker-compose-bigdata.yml logs -f --tail=20
